{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "147c3df8",
   "metadata": {},
   "source": [
    "# Lecture 2: Algorithm Analysis\n",
    "\n",
    "<font size = \"4\">\n",
    "\n",
    "Consider the computation of the following function:\n",
    "\n",
    "$$ f(n) = \\sum_{i=1}^n i = 1 + 2 + 3 + \\cdots + n$$\n",
    "\n",
    "There are two ways we could compute this function\n",
    "\n",
    "1. The \"naive\" approach - just sum up all the terms in a loop\n",
    "\n",
    "2. Use the closed-form expression for the sum:\n",
    "\n",
    "$$ f(n) = \\sum_{i=1}^n i = \\frac{n(n+1)}{2} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "11c60dc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55\n",
      "55\n"
     ]
    }
   ],
   "source": [
    "def sum_of_n(n):\n",
    "    the_sum = 0\n",
    "    for i in range(1, n + 1):\n",
    "        the_sum = the_sum + i\n",
    "    return the_sum\n",
    "\n",
    "def sum_of_n_2(n):\n",
    "    return int(n * (n + 1) / 2)\n",
    "\n",
    "\n",
    "print(sum_of_n(10))\n",
    "print(sum_of_n_2(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83105462",
   "metadata": {},
   "source": [
    "<font size = \"4\">\n",
    "\n",
    "Which one is faster? How can we tell?"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 2,
=======
   "execution_count": 10,
>>>>>>> upstream/main
   "id": "ce0880d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sum_of_n (loop):\n",
<<<<<<< HEAD
      "Sum is 5050. Required 1.2100e-05 seconds\n",
      "Sum is 5050. Required 6.7001e-06 seconds\n",
      "Sum is 5050. Required 6.3000e-06 seconds\n",
      "Sum is 5050. Required 6.0000e-06 seconds\n",
      "Sum is 5050. Required 6.0999e-06 seconds\n",
      "\n",
      "sum_of_n_2 (expression):\n",
      "Sum is 5050. Required 3.9000e-06 seconds\n",
      "Sum is 5050. Required 1.2000e-06 seconds\n",
      "Sum is 5050. Required 8.0001e-07 seconds\n",
      "Sum is 5050. Required 7.0001e-07 seconds\n",
      "Sum is 5050. Required 6.0000e-07 seconds\n"
=======
      "Sum is 5050. Required 6.0420e-06 seconds\n",
      "Sum is 5050. Required 3.4580e-06 seconds\n",
      "Sum is 5050. Required 3.1248e-06 seconds\n",
      "Sum is 5050. Required 3.0000e-06 seconds\n",
      "Sum is 5050. Required 2.7909e-06 seconds\n",
      "\n",
      "sum_of_n_2 (expression):\n",
      "Sum is 5050. Required 4.7919e-06 seconds\n",
      "Sum is 5050. Required 6.2515e-07 seconds\n",
      "Sum is 5050. Required 4.1700e-07 seconds\n",
      "Sum is 5050. Required 2.9197e-07 seconds\n",
      "Sum is 5050. Required 2.9104e-07 seconds\n"
>>>>>>> upstream/main
     ]
    }
   ],
   "source": [
    "from timeit import default_timer\n",
    "\n",
    "n = 100 \n",
    "\n",
    "print(\"sum_of_n (loop):\")\n",
    "for i in range(5):\n",
    "    start = default_timer()\n",
    "    val = sum_of_n(n)\n",
    "    end = default_timer()\n",
    "\n",
    "    print(f\"Sum is {val}. Required {end - start:.4e} seconds\")\n",
    "\n",
    "print()\n",
    "print(\"sum_of_n_2 (expression):\")\n",
    "\n",
    "for i in range(5):\n",
    "    start = default_timer()\n",
    "    val = sum_of_n_2(n)\n",
    "    end = default_timer()\n",
    "\n",
    "    print(f\"Sum is {val}. Required {end - start:.4e} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f6d074c",
   "metadata": {},
   "source": [
    "<font size = \"4\">\n",
    "\n",
    "The function `sum_of_n_2` seems to be faster, but the difference is marginal. What happens if we increase the problem size?\n",
    "\n",
    "Going forward, let's average the times of the 5 runs"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 3,
=======
   "execution_count": 13,
>>>>>>> upstream/main
   "id": "9863d159",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sum_of_n (loop):\n",
<<<<<<< HEAD
      "For n = 10000, the average time was 0.0010473799891769886 seconds\n",
      "For n = 100000, the average time was 0.009815959981642664 seconds\n",
      "For n = 1000000, the average time was 0.1140983399702236 seconds\n",
      "For n = 10000000, the average time was 0.9106577999889851 seconds\n",
      "\n",
      "sum_of_n_2 (expression):\n",
      "For n = 10000, the average time was 1.2800097465515138e-06 seconds\n",
      "For n = 100000, the average time was 1.1600088328123092e-06 seconds\n",
      "For n = 1000000, the average time was 6.600050255656242e-07 seconds\n",
      "For n = 10000000, the average time was 6.999820470809937e-07 seconds\n"
=======
      "For n = 10000, the average time was 0.0002838000189512968 seconds\n",
      "For n = 100000, the average time was 0.003314449777826667 seconds\n",
      "For n = 1000000, the average time was 0.0305971581954509 seconds\n",
      "For n = 10000000, the average time was 0.314046524791047 seconds\n",
      "\n",
      "sum_of_n_2 (expression):\n",
      "For n = 10000, the average time was 7.085967808961868e-07 seconds\n",
      "For n = 100000, the average time was 2.420041710138321e-07 seconds\n",
      "For n = 1000000, the average time was 1.916196197271347e-07 seconds\n",
      "For n = 10000000, the average time was 1.7499551177024842e-07 seconds\n"
>>>>>>> upstream/main
     ]
    }
   ],
   "source": [
    "n_vals = [10000, 100000, 1000000, 10000000]\n",
    "num_repeats = 5\n",
    "\n",
    "print(\"sum_of_n (loop):\")\n",
    "for n in n_vals:\n",
    "    total_time = 0\n",
    "    for i in range(num_repeats):\n",
    "        start = default_timer()\n",
    "        val = sum_of_n(n)\n",
    "        end = default_timer()\n",
    "\n",
    "        total_time += end - start\n",
    "    print(f\"For n = {n}, the average time was {total_time/num_repeats} seconds\")\n",
    "\n",
    "print()\n",
    "print(\"sum_of_n_2 (expression):\")\n",
    "for n in n_vals:\n",
    "    total_time = 0\n",
    "    for i in range(num_repeats):\n",
    "        start = default_timer()\n",
    "        val = sum_of_n_2(n)\n",
    "        end = default_timer()\n",
    "\n",
    "        total_time += end - start\n",
    "    print(f\"For n = {n}, the average time was {total_time/num_repeats} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f1d2e44",
   "metadata": {},
   "source": [
    "<font size = \"4\">\n",
    "\n",
    "- When we increase the size of $n$ by a factor of 10, the average runtime of `sum_of_n` also increases by a factor of 10.\n",
    "\n",
    "- However, we don't see this same behavior for `sum_of_n_2`\n",
    "\n",
    "We can understand the difference intuitively, but we can rigorously establish the cost of both algorithms using *algorithm analysis*\n",
    "\n",
    "First, here's another way of computing average runtimes using the `timeit.timeit` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e28267b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sum_of_n_2 (expression):\n",
      "For n = 10000, the average time was 1.8167076632380485e-07 seconds\n",
      "For n = 100000, the average time was 1.5832949429750442e-07 seconds\n",
      "For n = 1000000, the average time was 7.270905189216137e-07 seconds\n",
      "For n = 10000000, the average time was 1.6707926988601685e-07 seconds\n"
     ]
    }
   ],
   "source": [
    "from timeit import timeit\n",
    "\n",
    "n_vals = [10000, 100000, 1000000, 10000000]\n",
    "num_repeats = 100\n",
    "print(\"sum_of_n_2 (expression):\")\n",
    "\n",
    "for n in n_vals:\n",
    "    total_time = timeit(stmt = \"f(n)\", number = num_repeats, \n",
    "        globals = {\"f\" : sum_of_n_2, \"n\" : n})\n",
    "    print(f\"For n = {n}, the average time was {total_time/num_repeats} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aadeda9f",
   "metadata": {},
   "source": [
    "## **\"Big-Oh\" notation**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b57b1191",
   "metadata": {},
   "source": [
    "<font size = \"4\">\n",
    "\n",
    "One way to measure the cost of an algorithm is by simply counting the number of operations. Consider the first function:\n",
    "\n",
    "```python\n",
    "def sum_of_n(n):\n",
    "    the_sum = 0\n",
    "    for i in range(1, n + 1):\n",
    "        the_sum = the_sum + i\n",
    "    return the_sum\n",
    "```\n",
    "\n",
    "There are two kinds of operations:\n",
    "\n",
    "1. Assignment operations (with the \"=\" sign)\n",
    "2. Addition (with the \"+\" sign)\n",
    "\n",
    "There is 1 assignment operation before the loop, when we initialize `the_sum`. We pass through the loop $n$ times, and each time we perform 1 addition, followed by 1 assignment.\n",
    "\n",
    "Thus, there are $n + 1$ assignments, and $n$ additions. So the total number of operations is\n",
    "\n",
    "$$W(n) = \\textrm{work for ``sum\\_of\\_n\" }  =  2n + 1$$\n",
    "\n",
    "For the second function, \n",
    "\n",
    "```python\n",
    "def sum_of_n_2(n):\n",
    "    return int(n * (n + 1) / 2)\n",
    "```\n",
    "\n",
    "There is: \n",
    "\n",
    "- 1 addition\n",
    "- 1 multiplication\n",
    "- 1 division\n",
    "- 1 conversion to `int`\n",
    "\n",
    "So the total number of operations is\n",
    "\n",
    "$$W_2(n) = \\textrm{work for ``sum\\_of\\_n\\_2\" } =  4$$\n",
    "\n",
    "Note that for the second algorithm, the work is independent of the value of $n$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "967189da",
   "metadata": {},
   "source": [
    "### Work in \"Big-Oh\" notation\n",
    "\n",
    "<font size = \"4\">\n",
    "\n",
    "Computer scientists would write the cost of each algorithm as:\n",
    "\n",
    "$$W(n) = \\textrm{work for ``sum\\_of\\_n\" } = \\mathcal{O}(n)$$\n",
    "\n",
    "$$W_2(n) = \\textrm{work for ``sum\\_of\\_n\\_2\" } = \\mathcal{O}(1)$$\n",
    "\n",
    "What do these symbols mean? Why can we replace $2n+1$ with the symbol \"$\\mathcal{O}(n)$\", and replace $4$ with the symbol \"$\\mathcal{O}(1)$\"?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7096fe7e",
   "metadata": {},
   "source": [
    "### A closer look at $W(n)$\n",
    "\n",
    "<font size = \"4\">\n",
    "\n",
    "The cost of the first algorithm is $W(n) = 2n + 1$. However, we are most interested in what happens for **large** values of $n$. Put another way, we want to understand the cost as $n\\to \\infty$.\n",
    "\n",
    "When $n$ is very large, how much does the constant factor of $1$ really matter? Not much. When $n = 10^6$ (1 million), the difference between a cost of $2,000,000$ and a cost of $2,000,001$ is extremely insignificant.\n",
    "\n",
    "Ok, so $W(n) \\approx 2n$ seems very reasonable for large $n$. But can we really drop the factor of $2$? For $n = 10^6$, the difference between a cost of 1 million and 2 million hardly seems negligible.\n",
    "\n",
    "However, we are interested in **cost**, not just number of operations. If we had an infinitely fast computer, we could do as many operations as we wanted without any issue. However, computers are not infinitely fast."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec203cc9",
   "metadata": {},
   "source": [
    "<font size = \"4\">\n",
    "\n",
    "Suppose our computer performed 1 billion operations per second (probably an underestimate). Then the **total time** taken for the algorithm would be\n",
    "\n",
    "\\begin{align*}\n",
    "\\frac{W(n) \\textrm{ operations}}{10^9 \\frac{\\textrm{operations}}{\\textrm{second}}} &\\approx \\frac{2n \\textrm{ operations}}{10^9 \\frac{\\textrm{operations}}{\\textrm{second}}}\\\\\n",
    "&= 2 \\times 10^{-9}\\cdot n\\ \\textrm{seconds} \\\\\n",
    "&\\approx 10^{-9}\\cdot n\\ \\textrm{seconds}\n",
    "\\end{align*}\n",
    "\n",
    "In the grand scheme of things, the factor of $2$ really isn't important, at least compared to the value of $n$ (remember we are interested in large values of $n$). If we measured the cost in different units, like minutes or hours, we would get a different constant factor anyway. Instead of using operations per second we could use \"giga-operations\" per second (1 \"giga-operation\" equals 1 billion operations), and that would lead to a different constant factor too.\n",
    "\n",
    "**Dropping the constant factor makes the analysis agnostic to what units of measurement are being used**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3b238f2",
   "metadata": {},
   "source": [
    "<font size = \"4\">\n",
    "\n",
    "There's another reason to drop the constant factor $2$. The $2n$ operations inside the loop came from two places: there were $n$ addition operations, and $n$ assignment operations.\n",
    "\n",
    "Which operation does a computer do faster: addition or assignment? What about addition vs. multiplication vs. division vs. taking square roots? The answer is very **machine dependent**. Three or four decades ago, multiplication was much slower than addition. That isn't really the case anymore (some computers can do 1 addition and 1 multiplication in a single \"multiply-add\" instruction).\n",
    "\n",
    "To simplify things, we don't account for the differences in computational cost between different operations on our computer, or worry about how these change if we switch to a different machine. But if we ignore these details, the factor of \"2\" becomes quite meaningless.\n",
    "\n",
    "**Dropping the constant factor makes the analysis agnostic to what hardware is being used**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db9f3651",
   "metadata": {},
   "source": [
    "## **Definition of \"Big-Oh\"**\n",
    "\n",
    "<font size = \"4\">\n",
    "\n",
    "Let $f(n)$ and $g(n)$ be two functions. \n",
    "\n",
    "- We say that $f(n) = \\mathcal{O}(g(n))$ if there exists a constant $C > 0$ and a positive integer $N$ such that\n",
    "\n",
    "$$|f(n)| \\leq C\\cdot |g(n)|\\qquad \\textrm{for $n \\geq N$}$$\n",
    "\n",
    "This means when $n$ is large enough, the absolute value of $f(n)$ is bounded by the absolute value of $g(n)$ multiplied by a constant factor.\n",
    "\n",
    "- If $g(n) \\neq 0$ for sufficiently large $n$, we can rewrite this as: there exists a constant $C > 0$ and a positive integer $N$ such that\n",
    "\n",
    "$$\\frac{|f(n)|}{|g(n)|} \\leq C\\qquad \\textrm{for $n \\geq N$}$$\n",
    "\n",
    "- For those of us who are comfortable with real analysis, we can say: there exists a constant $C > 0$ such that\n",
    "\n",
    "$$\\limsup_{n\\to \\infty}\\frac{|f(n)|}{|g(n)|} \\leq C$$\n",
    "\n",
    "(ignore this if you aren't familiar with the concept of \"limit supremum\" a.k.a \"limit superior\")\n",
    "\n",
    "- In words, we typically say \"$f$ is Oh of $g$\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d673010",
   "metadata": {},
   "source": [
    "### Showing that $W(n) = 2n + 1 = \\mathcal{O}(n)$\n",
    "\n",
    "<font size = \"4\">\n",
    "\n",
    "- It is often the case that $f(n)$ and $g(n)$ are both positive functions, in which case we can ignore the absolute values.\n",
    "\n",
    "- Let $f(n) = 2n + 1$ and $g(n) = n$. Note that\n",
    "\n",
    "$$\\frac{f(n)}{g(n)} = \\frac{2n + 1}{n} = 2 + \\frac{1}{n} \\leq 3\\qquad \\textrm{for $n \\geq 1$}$$\n",
    "\n",
    "- Thus, taking $C = 3$ and $N = 1$, we see that $f(n) = \\mathcal{O}(g(n))$ or:\n",
    "\n",
    "$$2n + 1 = \\mathcal{O}(n)$$\n",
    "\n",
    "- Note that we could have also taken the constant $C$ to be 4, 5, 6, 500, or $10^{12}$. The statement remains true. We could have also taken $N = 2, 3, 4, 500, 10^{26}$. We could **not** have used $C = 2$ however."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb176125",
   "metadata": {},
   "source": [
    "### Showing that $W_2(n) = 4 = \\mathcal{O}(1)$\n",
    "\n",
    "<font size = \"4\">\n",
    "\n",
    "- Let $f(n) = 4$ and $g(n) = 1$ (both constant functions). Note that\n",
    "\n",
    "$$\\frac{f(n)}{g(n)} = \\frac{4}{1} = 4 \\leq 4\\qquad \\textrm{for $n \\geq 1$}$$\n",
    "\n",
    "- We took $C = 4$ and $N = 1$ above. We could have chosen any larger values too."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cbcc5a2",
   "metadata": {},
   "source": [
    "## **Big-Omega Notation**\n",
    "\n",
    "<font size = \"4\">\n",
    "\n",
    "Let $f(n)$ and $g(n)$ be two functions. \n",
    "\n",
    "- We say that $f(n) = \\mathcal{\\Omega}(g(n))$ if there exists a constant $c > 0$ and a positive integer $M$ such that\n",
    "\n",
    "$$c\\cdot |g(n)| \\leq |f(n)|\\qquad \\textrm{for $n \\geq M$}$$\n",
    "\n",
    "- If $g(n) \\neq 0$ for sufficiently large $n$, we can rewrite this as: there exists a constant $c > 0$ and a positive integer $M$ such that\n",
    "\n",
    "$$c \\leq \\frac{|f(n)|}{|g(n)|}\\qquad \\textrm{for $n \\geq M$}$$\n",
    "\n",
    "- For those of us who are comfortable with real analysis, we can say: there exists a constant $C > 0$ such that\n",
    "\n",
    "$$c \\leq \\liminf_{n\\to \\infty}\\frac{|f(n)|}{|g(n)|}$$\n",
    "\n",
    "(ignore this if you aren't familiar with the concept of \"limit infimum\" a.k.a \"limit inferior\")\n",
    "\n",
    "- **We have the following equivalence:**\n",
    "\n",
    "$$f(n) = \\mathcal{O}(g(n))\\quad \\textrm{if and only if}\\quad g(n) = \\mathcal{\\Omega}(f(n))$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faca5115",
   "metadata": {},
   "source": [
    "## **Meaning of Big-Oh and Big-Omega**\n",
    "\n",
    "<font size = \"4\">\n",
    "\n",
    "- If $f(n) = \\mathcal{O}(g(n))$, this means that for large values of $n$, the growth of $f(n)$ is **smaller than or equal to** the growth of $g(n)$. I.e., $g(n)$ provides an *upper* bound for the growth of $f(n)$.\n",
    "\n",
    "- If $f(n) = \\mathcal{\\Omega}(g(n))$, this means that for large values of $n$, the growth of $f(n)$ is **faster than or equal to** the growth of $g(n)$. I.e., $g(n)$ provides a *lower* bound for the growth of $f(n)$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1841380",
   "metadata": {},
   "source": [
    "## **Big-Theta Notation**\n",
    "\n",
    "<font size = \"4\">\n",
    "\n",
    "Let $f(n)$ and $g(n)$ be two functions. \n",
    "\n",
    "- We say that $f(n) = \\mathcal{\\Theta}(g(n))$ if both of the following statements are true:\n",
    "\n",
    "    1. $f(n) = \\mathcal{O}(g(n))$\n",
    "    2. $f(n) = \\mathcal{\\Omega}(g(n))$\n",
    "\n",
    "- This means that for large values of $n$, the growth of $f(n)$ is **equal to** the growth of $g(n)$.\n",
    "\n",
    "- Put another way $f(n)$ and $g(n)$ behave the same way for large $n$, up to unimportant constant factors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1e4468b",
   "metadata": {},
   "source": [
    "## **Examples**\n",
    "\n",
    "<font size = \"4\">\n",
    "\n",
    "- $n = \\mathcal{O}(n)$, &ensp; $5n = \\mathcal{O}(n)$,  &ensp;   $500n = \\mathcal{O}(n)$\n",
    "\n",
    "- $n = \\mathcal{\\Theta}(n)$, &ensp; $5n = \\mathcal{\\Theta}(n)$,  &ensp;   $500n = \\mathcal{\\Theta}(n)$\n",
    "- $1 = \\mathcal{O}(n)$, &ensp; $n \\neq \\mathcal{O}(1)$, &ensp; $n = \\mathcal{\\Omega}(1)$\n",
    "- $n + 500 = \\mathcal{O}(n)$,  &ensp; $n + 500 = \\mathcal{\\Theta}(n)$\n",
    "- $n = \\mathcal{O}(n^2)$, &ensp; $n \\neq \\mathcal{\\Theta}(n^2)$\n",
    "- $3n^2 + 2n + 4 = \\mathcal{O}(n^2)$, &ensp; $3n^2 + 2n + 4 = \\mathcal{\\Theta}(n^2)$,\n",
    "- For any positive integer $k$, $n^k = \\mathcal{O}(2^n)$, &ensp; $2^n = \\mathcal{\\Omega}(n^k)$, &ensp; $2^n \\neq \\mathcal{\\Theta}(n^k)$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c3bcc45",
   "metadata": {},
   "source": [
    "## **Common usage of Big-Oh notation**\n",
    "\n",
    "<font size = \"4\">\n",
    "\n",
    "- According to the definition, $f(n) = \\mathcal{O}(g(n))$ means $g(n)$ is an **upper bound** for the growth of $f(n)$ for large $n$.\n",
    "\n",
    "- By definition, $f(n) = \\mathcal{\\Theta}(g(n))$ means the growth of $f(n)$ and $g(n)$ are **equivalent**.\n",
    "\n",
    "- From the book *Cracking the Coding Interview*: \"In industry (and therefore in interviews), people seem to have merged $\\mathcal{\\Theta}$ and $\\mathcal{O}$ together. Industry's meaning of $\\mathcal{O}$ is closer to what academics mean by $\\mathcal{\\Theta}$\".\n",
    "\n",
    "- So the equality $n = \\mathcal{O}(n^2)$ is true by definition, but **you wouldn't want to say this in an interview**. This is because $n \\neq \\mathcal{\\Theta}(n^2)$\n",
    "\n",
    "- The online textbook also seems to use this slighly inaccurate terminology. Loosely speaking, we can think of Big-Oh notation as a way to describe the **dominant part** of a function $f(n)$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0013e7c",
   "metadata": {},
   "source": [
    "## **Sum of first $n$ natural numbers**\n",
    "\n",
    "<font size = \"4\">\n",
    "\n",
    "- We saw that the work (number of operations) for computing the sum $1 + 2 + \\cdots + n$ using a for loop was\n",
    "\n",
    "$$W(n) = 2n + 1 = \\mathcal{O}(n)$$\n",
    "\n",
    "- Indeed, it's also true that\n",
    "\n",
    "$$W(n) = 2n + 1 = \\mathcal{\\Theta}(n)$$\n",
    "\n",
    "- The cost of computing the sum with a for loop is **linear** with respect to $n$. If we double the value of $n$, the computational cost is also **doubled** (roughly speaking).\n",
    "\n",
    "- If we use the closed-form expression to compute the sum, the work is:\n",
    "\n",
    "$$W_2(n) = 4 = \\mathcal{O}(1)$$\n",
    "\n",
    "- Indeed, it's also true that \n",
    "\n",
    "$$W_2(n) = 4 = \\mathcal{\\Theta}(1)$$\n",
    "\n",
    "- The cost of computing the sum with the closed-form expression is **constant** with respect to $n$. If we double the value of $n$, the computational cost is **unchanged** (roughly speaking).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aac23d6",
   "metadata": {},
   "source": [
    "## **Hierarchy of Functions used in Big-Oh notation**\n",
    "\n",
    "<font size = \"4\">\n",
    "\n",
    "Here are common functions used in algorithm analysis. They are ordered from slowest to fastest in terms of growth. (We will use the \"industry\" definition of Big-Oh here)\n",
    "\n",
    "1. $f(n) = \\mathcal{O}(1)\\qquad$ Size of $f(n)$ is constant in $n$\n",
    "\n",
    "2. $f(n) = \\mathcal{O}(\\log n)\\qquad$ Size of $f(n)$ is logarithmic in $n$\n",
    "3. $f(n) = \\mathcal{O}(n)\\qquad$ Size of $f(n)$ is linear in $n$\n",
    "4. $f(n) = \\mathcal{O}(n\\log n)\\qquad$ Size of $f(n)$ is log linear in $n$\n",
    "5. $f(n) = \\mathcal{O}(n^2)\\qquad$ Size of $f(n)$ is quadratic in $n$\n",
    "6. $f(n) = \\mathcal{O}(n^3)\\qquad$ Size of $f(n)$ is cubic in $n$\n",
    "7. $f(n) = \\mathcal{O}(2^n)\\qquad$ Size of $f(n)$ is exponential in $n$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdc354c8",
   "metadata": {},
   "source": [
    "## **Another Code Example**\n",
    "\n",
    "<font size = \"4\">\n",
    "\n",
    "Consider the following (ultimately pointless) code fragment. What is the computational cost?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0a78205d",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10\n",
    "\n",
    "##### Start code fragment\n",
    "a = 5\n",
    "b = 6\n",
    "c = 10\n",
    "for i in range(n):\n",
    "    for j in range(n):\n",
    "        x = i * i\n",
    "        y = j * j\n",
    "        z = i * j\n",
    "for k in range(n):\n",
    "    w = a * k + 45\n",
    "    v = b * b\n",
    "d = 33\n",
    "### End code fragment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "676f2c3c",
   "metadata": {},
   "source": [
    "<font size = \"4\">\n",
    "\n",
    "- There are 4 assignments for `a`, `b`, `c`, and `d`\n",
    "\n",
    "- We pass through the nested for-loop $n^2$ times. There are 3 multiplications and 3 assignments, for a total of $6n^2$ operations.\n",
    "\n",
    "- We pass through the second for loop $n$ times. There are 2 multiplications, 1 addition, and 2 assignments, for a total of $5n$ operations.\n",
    "\n",
    "- The total cost is thus $W(n) = 6n^2 + 5n + 4$. We can thus write:\n",
    "\n",
    "$$W(n) = \\mathcal{O}(n^2)$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bab9a702",
   "metadata": {},
   "source": [
    "## **Other notation to be aware of**\n",
    "\n",
    "### Little-oh notation\n",
    "\n",
    "<font size = \"4\">\n",
    "\n",
    "Let $f(n)$ and $g(n)$ be two functions. We write $f(n) = \\mathcal{o}(g(n))$ if\n",
    "\n",
    "$$ \\lim_{n\\to\\infty} \\frac{|f(n)|}{|g(n)|} = 0$$\n",
    "\n",
    "We say $f(n)$ is \"little-oh\" of $g(n)$. This means $|g(n)|$ grows **strictly faster** than $|f(n)|$.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a053bb78",
   "metadata": {},
   "source": [
    "### Asymptotic Notation\n",
    "\n",
    "<font size = \"4\">\n",
    "\n",
    "- There **are** scenarios when constant factors are important. For example, once we have selected a given computer, an algorithm with cost equal to $2n + 1$ will probably be more expensive than an algorithm with cost equal to $n + 1$.\n",
    "\n",
    "- If $f(n)$ and $g(n)$ are functions, we write $f(n) \\sim g(n)$ if\n",
    "\n",
    "$$\\lim_{n\\to\\infty}\\frac{f(n)}{g(n)} = 1$$\n",
    "\n",
    "- For example, the work to compute $1 + 2 + \\cdots + n$ by using a for loop satisfies\n",
    "\n",
    "$$\\lim_{n\\to\\infty} \\frac{W(n)}{2n} = \\lim_{n\\to\\infty} \\frac{2n + 1}{2n} = \\lim_{n\\to\\infty} \\left(1 + \\frac{1}{2n}\\right) = 1$$\n",
    "\n",
    "- So in this case, we would write\n",
    "\n",
    "$$ W(n) \\sim 2n$$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
